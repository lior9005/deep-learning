{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ec0430e926941248bb5781eb556aef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79ee1c12e2104e61a00c1312751cde9a",
              "IPY_MODEL_9cd40add33624ce6b1463e937a1348ae",
              "IPY_MODEL_a56bbf18c8934427b07d4e90d5ad716f"
            ],
            "layout": "IPY_MODEL_a0820c5d071b4bcda1e44610f3846ffd"
          }
        },
        "79ee1c12e2104e61a00c1312751cde9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2371813f710944f5b6197dfc30379b7e",
            "placeholder": "​",
            "style": "IPY_MODEL_ba3e6ebaafe248c6bdead2189e879194",
            "value": "Training OSR Model:  84%"
          }
        },
        "9cd40add33624ce6b1463e937a1348ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b71ad22b9ab04a54bcc264f59f42ee26",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abb0cd23054c4672ad49987f88d99b95",
            "value": 21
          }
        },
        "a56bbf18c8934427b07d4e90d5ad716f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1ae6ee647b24e6fa3050d85d8e58ec7",
            "placeholder": "​",
            "style": "IPY_MODEL_d4e4f12aa5b141be864e5bd009341c02",
            "value": " 21/25 [13:35&lt;02:30, 37.73s/it]"
          }
        },
        "a0820c5d071b4bcda1e44610f3846ffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2371813f710944f5b6197dfc30379b7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba3e6ebaafe248c6bdead2189e879194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b71ad22b9ab04a54bcc264f59f42ee26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abb0cd23054c4672ad49987f88d99b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1ae6ee647b24e6fa3050d85d8e58ec7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4e4f12aa5b141be864e5bd009341c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lior9005/deep-learning/blob/main/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ADL final project\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Authors:**\n",
        "> Lior Sharony 316380138\n",
        "\n",
        "\n",
        "> Noam Zigler 208742429\n",
        "\n",
        "\n",
        "> Eden Miran 314868019\n"
      ],
      "metadata": {
        "id": "HlHgPOjlULwb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6Z1nbKeST4aX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49a7799c-f28d-485c-e51c-cbf318f2938f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset, random_split, Subset, Dataset, SubsetRandomSampler\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "\n",
        "# Eval mode\n",
        "eval_mode = False\n",
        "ood_as_fashion = False #define the ood\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.2. Data & Preprocessing"
      ],
      "metadata": {
        "id": "x64L0Fk9XASM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OSR Dataset template\n",
        "class CombinedDataset(Dataset):\n",
        "    def __init__(self, mnist, ood, transform_mnist=None, transform_ood=None):\n",
        "        self.mnist = mnist\n",
        "        self.ood = ood\n",
        "        # transforms could be defined either here or when you init each dataset.\n",
        "        self.transform_mnist = transform_mnist\n",
        "        self.transform_ood = transform_ood\n",
        "\n",
        "    def __len__(self):\n",
        "        # combined length of MNIST and OOD\n",
        "        return len(self.mnist) + len(self.ood)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx < len(self.mnist):\n",
        "            # if index is within the range of MNIST, return MNIST data and label\n",
        "            data, label = self.mnist[idx]\n",
        "            if self.transform_mnist:\n",
        "                data = self.transform_mnist(data)\n",
        "            return data, label\n",
        "        else:\n",
        "            # if index is beyond the range of MNIST, return OOD data and 10 as label\n",
        "            data, _ = self.ood[idx - len(self.mnist)]  # adjust index for OOD\n",
        "            if self.transform_ood:\n",
        "                data = self.transform_ood(data)\n",
        "            return data, 10  # OOD label is always 10\n"
      ],
      "metadata": {
        "id": "1frlbyepYerE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformers\n",
        "mnist_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "ood_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Mnist dataset\n",
        "mnist_train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=mnist_transform)\n",
        "mnist_test_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=mnist_transform)\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "num_of_train_samples = 5000\n",
        "num_of_test_samples = 2000\n",
        "\n",
        "train_size = len(mnist_train_set)\n",
        "mnist_val_size = int(train_size * 0.2)\n",
        "mnist_train_size = train_size - mnist_val_size\n",
        "mnist_train_dataset, mnist_val_dataset = random_split(mnist_train_set, [mnist_train_size, mnist_val_size])\n",
        "\n",
        "train_idx = np.arange(len(mnist_train_dataset))\n",
        "train_subset_idx = np.random.choice(train_idx,num_of_train_samples)\n",
        "train_subset_sampler = SubsetRandomSampler(train_subset_idx)\n",
        "\n",
        "mnist_train_loader = DataLoader(mnist_train_dataset, batch_size=512, sampler=train_subset_sampler)\n",
        "mnist_val_loader = DataLoader(mnist_val_dataset, batch_size=512, shuffle=False)\n",
        "mnist_test_loader = DataLoader(mnist_test_set, batch_size=1000, shuffle=False)\n",
        "\n",
        "# Ood\n",
        "if(ood_as_fashion):\n",
        "  ood = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=ood_transform)\n",
        "else:\n",
        "  ood = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=ood_transform)\n",
        "\n",
        "# Generating the combined dataset\n",
        "ood_indices = np.random.choice(len(ood), num_of_test_samples , replace=False)\n",
        "ood_subset = Subset(ood, ood_indices)\n",
        "mnist_test_subset_idx = np.random.choice(len(mnist_test_set), num_of_test_samples, replace=False)\n",
        "mnist_test_subset = Subset(mnist_test_set, mnist_test_subset_idx)\n",
        "\n",
        "combined_ds = CombinedDataset(mnist_test_subset, ood_subset)\n",
        "combined_ds_loader = DataLoader(combined_ds, batch_size=1024, shuffle=True)\n"
      ],
      "metadata": {
        "id": "hBVUYatNUKQp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3bdad7c-7cad-401d-b87b-fbe86e86bf45"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.3. Models"
      ],
      "metadata": {
        "id": "jJh6x5CLXGVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline model class\n",
        "class Baseline_model(nn.Module):\n",
        "  def __init__(self):\n",
        "        super(Baseline_model, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "          )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels=64, out_channels=1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "        )\n",
        "\n",
        "        self.clf = nn.Sequential(\n",
        "            nn.Linear(self._get_conv_output(), 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "  def _get_conv_output(self, shape = (1,28,28)):\n",
        "    #Computes the size of the flattened features after the convolutional layers.\n",
        "      with torch.no_grad():\n",
        "          batch_size = 1\n",
        "          input = torch.rand(batch_size, *shape)\n",
        "          output_feat = self.encoder(input)\n",
        "          n_size = output_feat.view(batch_size, -1).shape[1]\n",
        "      return n_size\n",
        "\n",
        "  def forward(self,x):\n",
        "      encoded_vector = self.encoder(x)\n",
        "      encoded_vector_clf = encoded_vector.view(encoded_vector.size(0), -1)\n",
        "      pred = self.clf(encoded_vector_clf)\n",
        "      recon = self.decoder(encoded_vector)\n",
        "      return pred, recon\n",
        "\n",
        "class OSR_model(nn.Module):\n",
        "    def __init__(self, recon_threshold = float('inf'), softmax_threshold = -float('inf'), n_classes=11, use_clustering=True):\n",
        "        super(OSR_model, self).__init__()\n",
        "\n",
        "        # Encoder (same as in Baseline model)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Decoder (same as in Baseline model)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(in_channels=64, out_channels=1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "        )\n",
        "\n",
        "        # Classifier (same as in Baseline model)\n",
        "        self.clf = nn.Sequential(\n",
        "            nn.Linear(self._get_conv_output(), n_classes),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "        # Reconstruction threshold (to decide if the sample is unknown)\n",
        "        self.recon_threshold = recon_threshold\n",
        "        self.softmax_threshold = softmax_threshold\n",
        "        self.n_classes = n_classes\n",
        "        self.use_clustering = use_clustering\n",
        "        self.kmeans = None  # Placeholder for clustering\n",
        "\n",
        "    def _get_conv_output(self, shape=(1, 28, 28)):\n",
        "        \"\"\"Computes the size of the flattened features after the convolutional layers.\"\"\"\n",
        "        with torch.no_grad():\n",
        "            batch_size = 1\n",
        "            input = torch.rand(batch_size, *shape)\n",
        "            output_feat = self.encoder(input)\n",
        "            n_size = output_feat.view(batch_size, -1).shape[1]\n",
        "        return n_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded_vector = self.encoder(x)\n",
        "        encoded_vector_clf = encoded_vector.view(encoded_vector.size(0), -1)\n",
        "        pred = self.clf(encoded_vector_clf)\n",
        "        recon = self.decoder(encoded_vector)\n",
        "\n",
        "        # Calculate reconstruction error\n",
        "        recon_error = F.mse_loss(recon, x, reduction='none')\n",
        "        recon_error = recon_error.view(recon_error.size(0), -1).mean(dim=1)  # Sum across pixels\n",
        "\n",
        "        max_softmax_confidence, _ = pred.max(dim=1)\n",
        "\n",
        "        # Check if reconstruction error exceeds the threshold\n",
        "        is_unknown_recon = recon_error > self.recon_threshold\n",
        "\n",
        "        # Check if softmax confidence is below the threshold\n",
        "        is_unknown_softmax = max_softmax_confidence < self.softmax_threshold\n",
        "\n",
        "        # Combine both thresholds: if either condition is true, mark as unknown\n",
        "        #is_unknown = is_unknown_recon | is_unknown_softmax  # Logical OR to combine the two conditions\n",
        "        is_unknown = is_unknown_recon\n",
        "\n",
        "        if not self.training:\n",
        "            # Update predictions for unknown samples\n",
        "            unknown_class_index = self.clf[0].out_features - 1  # Assuming the unknown class is the last index\n",
        "            pred[is_unknown] = torch.full((pred.size(1),), -float('inf'), device=pred.device)  # Set log probabilities to -inf\n",
        "            pred[is_unknown, unknown_class_index] = 0  # Set log probability of the unknown class to 0 (highest)\n",
        "\n",
        "        return pred, recon, is_unknown, recon_error, encoded_vector_clf\n",
        "\n",
        "    def fit_clustering(self, train_loader):\n",
        "        \"\"\"\n",
        "        Fit a clustering model (e.g., KMeans) on the encoded vectors of the known classes\n",
        "        \"\"\"\n",
        "        encoded_vectors = []\n",
        "        labels = []\n",
        "\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            for inputs, lbls in train_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                encoded_vector = self.encoder(inputs)\n",
        "                encoded_vector = encoded_vector.view(encoded_vector.size(0), -1)\n",
        "                encoded_vectors.append(encoded_vector.cpu().numpy())\n",
        "                labels.extend(lbls.cpu().numpy())\n",
        "\n",
        "        encoded_vectors = np.vstack(encoded_vectors)\n",
        "        labels = np.array(labels)\n",
        "\n",
        "        # Fit k-means clustering on the encoded vectors of the known classes\n",
        "        self.kmeans = KMeans(n_clusters=self.n_classes, random_state=42)\n",
        "        self.kmeans.fit(encoded_vectors)\n",
        "\n",
        "        # Map clusters to the MNIST labels (based on majority voting)\n",
        "        self.cluster_to_label = {}\n",
        "        for i in range(self.n_classes):\n",
        "            cluster_idx = np.where(self.kmeans.labels_ == i)[0]\n",
        "            cluster_labels = labels[cluster_idx]\n",
        "            most_common_label = np.bincount(cluster_labels).argmax()\n",
        "            self.cluster_to_label[i] = most_common_label\n",
        "\n",
        "    def predict_class_from_cluster(self, encoded_vector):\n",
        "        \"\"\"\n",
        "        Predict the class based on clustering\n",
        "        \"\"\"\n",
        "        cluster_idx = self.kmeans.predict(encoded_vector)\n",
        "        return self.cluster_to_label[cluster_idx[0]]\n",
        "\n",
        "    def determine_threshold(self, digit_loader, percentile=95):\n",
        "        self.eval()  # Set model to evaluation mode\n",
        "        recon_errors = []\n",
        "        softmax_confidences = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, _ in digit_loader:  # Assuming DataLoader returns (images, labels)\n",
        "                images = images.to(next(self.parameters()).device)  # Move images to the same device as the model\n",
        "                pred, recon, is_unknown, recon_error, encoded_vector_clf = self(images)\n",
        "\n",
        "                # Calculate reconstruction error\n",
        "                error = F.mse_loss(recon, images, reduction='none')\n",
        "                error = error.view(error.size(0), -1).mean(dim=1)\n",
        "                recon_errors.extend(error.cpu().numpy())\n",
        "\n",
        "                # Calculate softmax probabilities and confidence\n",
        "                max_softmax_confidence, _ = pred.max(dim=1)\n",
        "                softmax_confidences.extend(max_softmax_confidence.cpu().numpy())\n",
        "\n",
        "        # Calculate reconstruction error threshold based on the specified percentile\n",
        "        recon_threshold = np.percentile(recon_errors, percentile)\n",
        "\n",
        "        # Calculate softmax confidence threshold based on the specified percentile\n",
        "        softmax_confidence_threshold = np.percentile(softmax_confidences, 100 -percentile)\n",
        "\n",
        "        # Store the thresholds in the model\n",
        "        self.recon_threshold = recon_threshold\n",
        "        self.softmax_confidence_threshold = softmax_confidence_threshold\n",
        "\n",
        "        #return recon_threshold, softmax_confidence_threshold\n",
        "        return recon_threshold\n",
        "\n"
      ],
      "metadata": {
        "id": "9k2F1LYhWPxF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.4. Training"
      ],
      "metadata": {
        "id": "dtoW4thDXOU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not (eval_mode):\n",
        "\n",
        "  def train_baseline_model(model, train_loader, val_loader, clf_criterion, recon_criterion, optimizer, num_epochs):\n",
        "    # Dictionary to store training and validation statistics\n",
        "    results_dict = {\n",
        "        'train_clf_loss': [],\n",
        "        'val_clf_loss': [],\n",
        "        'train_recon_loss': [],\n",
        "        'val_recon_loss': [],\n",
        "        'val_acc': [],\n",
        "        'train_acc': []\n",
        "    }\n",
        "\n",
        "    # Loop over each epoch\n",
        "    for epoch in tqdm(range(num_epochs), desc=\"Training MNIST MLP\"):\n",
        "        for phase in ['train', 'val']:  # Training phase and validation phase\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()  # Set model to evaluation mode\n",
        "                dataloader = val_loader\n",
        "\n",
        "            # Initialize statistics for loss and accuracy\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            total_samples = 0\n",
        "            running_recon_loss = 0.0\n",
        "\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass (with gradient tracking during training)\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get outputs and reconstructions from the model\n",
        "                    outputs, recon = model(inputs)\n",
        "\n",
        "                    # Classifier loss (CrossEntropyLoss)\n",
        "                    clf_loss = clf_criterion(outputs, labels)\n",
        "\n",
        "                    # Reconstruction loss (Mean Squared Error)\n",
        "                    recon_loss = recon_criterion(recon, inputs)\n",
        "\n",
        "                    # Total loss is the sum of classifier and reconstruction loss\n",
        "                    total_loss = clf_loss + recon_loss\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        # Backpropagation and optimizer step during training\n",
        "                        total_loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Update statistics for both loss and accuracy\n",
        "                running_loss += total_loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(torch.argmax(outputs, 1) == labels.data)\n",
        "                running_recon_loss += recon_loss.item() * inputs.size(0)\n",
        "                total_samples += labels.size(0)\n",
        "\n",
        "            # Calculate average loss and accuracy for the epoch\n",
        "            epoch_clf_loss = running_loss / total_samples\n",
        "            epoch_clf_acc = running_corrects.double() / total_samples\n",
        "            epoch_recon_loss = running_recon_loss / total_samples\n",
        "\n",
        "            # Store results\n",
        "            results_dict[f'{phase}_clf_loss'].append(epoch_clf_loss)\n",
        "            results_dict[f'{phase}_acc'].append(epoch_clf_acc.item())\n",
        "            results_dict[f'{phase}_recon_loss'].append(epoch_recon_loss)\n",
        "    return results_dict\n",
        "\n",
        "  # OSR model training function\n",
        "  def train_osr_model(model, train_loader, val_loader, clf_criterion, recon_criterion, optimizer, num_epochs, recon_threshold=0.1, softmax_threshold=0.1):\n",
        "      results_dict = {\n",
        "          'train_clf_loss': [],\n",
        "          'val_clf_loss': [],\n",
        "          'train_recon_loss': [],\n",
        "          'val_recon_loss': [],\n",
        "          'train_acc': [],\n",
        "          'val_acc': [],\n",
        "          'train_unknown': [],\n",
        "          'val_unknown': []\n",
        "      }\n",
        "\n",
        "      for epoch in tqdm(range(num_epochs), desc=\"Training OSR Model\"):\n",
        "          for phase in ['train', 'val']:\n",
        "              if phase == 'train':\n",
        "                  model.train()\n",
        "                  dataloader = train_loader\n",
        "              else:\n",
        "                  model.eval()\n",
        "                  dataloader = val_loader\n",
        "\n",
        "              running_loss = 0.0\n",
        "              running_corrects = 0\n",
        "              total_samples = 0\n",
        "              running_recon_loss = 0.0\n",
        "              running_unknown = 0\n",
        "\n",
        "              for inputs, labels in dataloader:\n",
        "                  inputs = inputs.to(device)\n",
        "                  labels = labels.to(device)\n",
        "\n",
        "                  optimizer.zero_grad()\n",
        "\n",
        "                  with torch.set_grad_enabled(phase == 'train'):\n",
        "                      # Forward pass\n",
        "                      pred, recon, is_unknown, recon_error, encoded_vector_clf = model(inputs)\n",
        "\n",
        "                      # Calculate classification loss for known classes (0-9)\n",
        "                      clf_loss = clf_criterion(pred, labels)\n",
        "\n",
        "                      # Calculate reconstruction loss\n",
        "                      recon_loss = recon_criterion(recon, inputs)\n",
        "\n",
        "                      # Use a combined loss: classification loss + reconstruction loss\n",
        "                      total_loss = clf_loss + recon_loss\n",
        "\n",
        "                      # Backpropagation during training\n",
        "                      if phase == 'train':\n",
        "                          total_loss.backward()\n",
        "                          optimizer.step()\n",
        "\n",
        "                      # Update statistics\n",
        "                      running_loss += total_loss.item() * inputs.size(0)\n",
        "                      running_corrects += torch.sum(torch.argmax(pred, 1) == labels.data)\n",
        "                      running_recon_loss += recon_loss.item() * inputs.size(0)\n",
        "                      running_unknown += torch.sum(is_unknown).item()  # Count how many are marked as unknown\n",
        "                      total_samples += labels.size(0)\n",
        "\n",
        "              epoch_clf_loss = running_loss / total_samples\n",
        "              epoch_clf_acc = running_corrects.double() / total_samples\n",
        "              epoch_recon_loss = running_recon_loss / total_samples\n",
        "              epoch_unknown = running_unknown / total_samples\n",
        "\n",
        "              # Store results\n",
        "              results_dict[f'{phase}_clf_loss'].append(epoch_clf_loss)\n",
        "              results_dict[f'{phase}_acc'].append(epoch_clf_acc.item())\n",
        "              results_dict[f'{phase}_recon_loss'].append(epoch_recon_loss)\n",
        "              results_dict[f'{phase}_unknown'].append(epoch_unknown)\n",
        "\n",
        "      #model.recon_threshold, model.softmax_threshold = model.determine_threshold(val_loader, percentile=95)\n",
        "      model.recon_threshold = model.determine_threshold(val_loader, percentile=95)\n",
        "\n",
        "      return results_dict\n",
        "\n",
        "\n",
        "\n",
        "  def plot_training_results(result_dict):\n",
        "    plt.plot(result_dict['train_acc'], label='Training Accuracy')\n",
        "    plt.plot(result_dict['val_acc'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    final_train_acc = result_dict['train_acc'][-1]\n",
        "    final_val_acc = result_dict['val_acc'][-1]\n",
        "    offset = 0.5\n",
        "    plt.text(len(result_dict['train_acc']) - 1, final_train_acc, f'{final_train_acc*100:.2f}%', ha='right', va='bottom')\n",
        "    plt.text(len(result_dict['val_acc']) - 1, final_val_acc, f'{final_val_acc*100:.2f}%', ha='right', va='bottom')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(result_dict['train_clf_loss'], label='Training clf Loss')\n",
        "    plt.plot(result_dict['train_recon_loss'], label='Training recon Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    final_clf_train_loss =result_dict['train_clf_loss'][-1]\n",
        "    final_recon_train_loss = result_dict['train_recon_loss'][-1]\n",
        "    plt.text(len(result_dict['train_clf_loss']) - 1, final_clf_train_loss, f'{final_clf_train_loss:.2f}', ha='right', va='bottom')\n",
        "    plt.text(len(result_dict['train_recon_loss']) - 1, final_recon_train_loss, f'{final_recon_train_loss:.2f}', ha='right', va='bottom')\n",
        "    plt.show()\n",
        "\n",
        "  # Training and validation loss and accuracy for MNIST plot - baseline model\n",
        "  baseline_num_epoch = 20\n",
        "  baseline_model = Baseline_model().to(device)\n",
        "  lr = 0.1\n",
        "  clf_criterion = nn.NLLLoss()\n",
        "  recon_criterion = nn.MSELoss()\n",
        "  optimizer = optim.SGD(baseline_model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "  # result_dict = train_baseline_model(baseline_model,mnist_train_loader, mnist_val_loader, clf_criterion, recon_criterion, optimizer, baseline_num_epoch)\n",
        "  # plot_training_results(result_dict)\n",
        "\n",
        "    # Training and validation loss and accuracy for MNIST plot - osr model\n",
        "  OSR_num_epoch = 25\n",
        "  osr_model = OSR_model().to(device)\n",
        "  lr = 0.1\n",
        "  clf_criterion = nn.NLLLoss()\n",
        "  recon_criterion = nn.MSELoss()\n",
        "  optimizer = optim.SGD(osr_model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "  result_dict = train_osr_model(osr_model,mnist_train_loader, mnist_val_loader, clf_criterion, recon_criterion, optimizer, OSR_num_epoch)\n",
        "  plot_training_results(result_dict)\n",
        "\n",
        "# save the weights\n",
        "  torch.save(baseline_model.state_dict(), './baseline model.pth')\n",
        "  torch.save(osr_model.state_dict(), './OSR model.pth')"
      ],
      "metadata": {
        "id": "-VFZ1OstXQ04",
        "outputId": "0a83e45c-417a-4b59-e889-29204e123e2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2ec0430e926941248bb5781eb556aef9",
            "79ee1c12e2104e61a00c1312751cde9a",
            "9cd40add33624ce6b1463e937a1348ae",
            "a56bbf18c8934427b07d4e90d5ad716f",
            "a0820c5d071b4bcda1e44610f3846ffd",
            "2371813f710944f5b6197dfc30379b7e",
            "ba3e6ebaafe248c6bdead2189e879194",
            "b71ad22b9ab04a54bcc264f59f42ee26",
            "abb0cd23054c4672ad49987f88d99b95",
            "a1ae6ee647b24e6fa3050d85d8e58ec7",
            "d4e4f12aa5b141be864e5bd009341c02"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training OSR Model:   0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ec0430e926941248bb5781eb556aef9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.5 Evaluation - CIFAR10/Fashion-MNIST"
      ],
      "metadata": {
        "id": "MP2IFBDFXm_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Baseline results:##"
      ],
      "metadata": {
        "id": "psd09Ri388iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (eval_mode):\n",
        "    # Load the trained models weights\n",
        "    baseline_model = Baseline_model()\n",
        "    baseline_model.load_state_dict(torch.load('./baseline model.pth'))\n",
        "    baseline_model.to(device)\n",
        "    baseline_model.eval()\n",
        "    osr_model = OSR_model()\n",
        "    osr_model.load_state_dict(torch.load('./OSR model.pth'))\n",
        "    osr_model.to(device)\n",
        "    osr_model.eval()\n",
        "\n",
        "def eval_baseline(model, testloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predicted = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            labels = labels.to(device)\n",
        "            images = images.to(device)\n",
        "            outputs, _  = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Accumulate predictions and labels for confusion matrix\n",
        "            all_predicted.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_predicted)\n",
        "\n",
        "    return accuracy, cm\n",
        "\n",
        "# Baseline results\n",
        "accuracy, cm = eval_baseline(baseline_model, mnist_test_loader)\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=range(10), yticklabels=range(10))\n",
        "plt.title(f\"Confusion Matrix - Mnist test set, accuracy: {accuracy:.2f}%\")\n",
        "plt.ylabel(\"Actual Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "srzL6sAKXqNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.5.3. OSR approach:##\n",
        "\n",
        "TO FILL\n",
        "❌-❌❌❌❌❌❌❌❌❌--\n",
        "\n"
      ],
      "metadata": {
        "id": "u-XqV0ZOYDeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OOD results\n",
        "def map_to_binary_class(predictions, true_labels, known_class=0, unknown_class=1):\n",
        "    # Map MNIST labels to known (0) and OOD labels to unknown (1)\n",
        "    true_labels_mapped = torch.where(true_labels < 10, known_class, unknown_class)  # MNIST labels are < 10\n",
        "    predictions_mapped = torch.where(predictions < 10, known_class, unknown_class)  # Same for predicted values\n",
        "    return true_labels_mapped, predictions_mapped\n",
        "\n",
        "def OOD_res(model, testloader):\n",
        "  # Collect true labels and predictions\n",
        "  all_true_labels = []\n",
        "  all_predictions = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for images, labels in combined_ds_loader:\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "          # Get model predictions\n",
        "          outputs, _, _, _, _ = model(images)\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "          # Map labels and predictions to binary classes\n",
        "          true_labels_mapped, predictions_mapped = map_to_binary_class(predicted, labels)\n",
        "\n",
        "          all_true_labels.extend(true_labels_mapped.cpu().numpy())\n",
        "          all_predictions.extend(predictions_mapped.cpu().numpy())\n",
        "\n",
        "  # Calculate binary classification accuracy\n",
        "  accuracy = accuracy_score(all_true_labels, all_predictions)\n",
        "  print(f\"Binary classification accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "  # Generate confusion matrix\n",
        "  cm = confusion_matrix(all_true_labels, all_predictions)\n",
        "\n",
        "  # Plot the confusion matrix\n",
        "  plt.figure(figsize=(6, 5))\n",
        "  sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Known', 'Unknown'], yticklabels=['Known', 'Unknown'])\n",
        "  plt.xlabel('Predicted')\n",
        "  plt.ylabel('True')\n",
        "  plt.title('Confusion Matrix - Binary classification')\n",
        "  plt.show()\n",
        "\n",
        "#osr_model.recon_threshold, osr_model.softmax_threshold = osr_model.determine_threshold(mnist_val_loader, 97)\n",
        "osr_model.recon_threshold = osr_model.determine_threshold(mnist_val_loader, 97)\n",
        "print(f\"Threshold: {osr_model.recon_threshold}\")\n",
        "print(f\"Confidence threshold: {osr_model.softmax_threshold}\")\n",
        "OOD_res(osr_model, combined_ds_loader)\n",
        "\n",
        "# OSR results\n",
        "\n",
        "def eval_model(model, data_loader, device):\n",
        "    \"\"\" Evaluation function for the OSR task.\n",
        "    Given your OSR predictions, comptues the accuracy on MNIST, OOD set and both.\n",
        "    Note - this function does NOT computes the MNIST baseline accruacy.\n",
        "    Returns:\n",
        "     - acc_mnist\n",
        "     - acc_ood\n",
        "     - acc_total\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure model is in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    correct_mnist = 0\n",
        "    total_mnist = 0\n",
        "    correct_ood = 0\n",
        "    total_ood = 0\n",
        "\n",
        "    # No need to track gradients for evaluation, saves memory and computations\n",
        "    with torch.no_grad():\n",
        "        for data, labels in data_loader:\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "            # Model outputs\n",
        "            outputs, _, _, _, _ = model(data)\n",
        "\n",
        "\n",
        "            # y pred should be a vector of size (N_batch,) -> [5, 2, ..., 10]\n",
        "            # and not one-hot. You can handle this either in your model or here.\n",
        "\n",
        "            # Assuming the model returns an (N_batch, 11) size output\n",
        "            probas, y_pred = torch.max(outputs, 1)\n",
        "\n",
        "            # Split MNIST and OOD predictions and labels\n",
        "            # Assuming numerical labels, which is MNIST/CIFAR datasets default\n",
        "            # Note: Not one-hot!\n",
        "            mask_mnist = labels < 10\n",
        "            mask_ood = ~mask_mnist\n",
        "            labels_mnist = labels[mask_mnist]\n",
        "            labels_ood = labels[mask_ood]\n",
        "\n",
        "            pred_mnist = y_pred[mask_mnist]\n",
        "            pred_ood = y_pred[mask_ood]\n",
        "\n",
        "            total_mnist += labels_mnist.size(0)\n",
        "            total_ood += labels_ood.size(0)\n",
        "            correct_mnist += (pred_mnist == labels_mnist).sum().item()\n",
        "            correct_ood += (pred_ood == labels_ood).sum().item()\n",
        "\n",
        "    acc_mnist = correct_mnist / total_mnist\n",
        "    acc_ood = correct_ood / total_ood\n",
        "    acc_total = (correct_mnist + correct_ood) / (total_mnist + total_ood)\n",
        "\n",
        "    return acc_mnist, acc_ood, acc_total\n",
        "\n",
        "def OSR_cm(model, testloader, acc_mnist, acc_ood, acc_total):\n",
        "\n",
        "    # Generate confusion matrix (11 classes: 10 MNIST classes + 1 OOD class)\n",
        "    conf_matrix = np.zeros((11, 11), dtype=int)\n",
        "\n",
        "    # Collect all predictions and labels for confusion matrix\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data, labels in testloader:\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "            outputs, _, _, _, _ = model(data)\n",
        "            probas, y_pred = torch.max(outputs, 1)\n",
        "\n",
        "            # Separate MNIST and OOD samples\n",
        "            mask_mnist = labels < 10\n",
        "            mask_ood = ~mask_mnist\n",
        "\n",
        "            labels_mnist = labels[mask_mnist]\n",
        "            labels_ood = torch.full_like(labels[mask_ood], 10)  # Treat OOD as class 10\n",
        "\n",
        "            pred_mnist = y_pred[mask_mnist]\n",
        "            pred_ood = y_pred[mask_ood]\n",
        "\n",
        "            # Update confusion matrix for MNIST\n",
        "            for true, pred in zip(labels_mnist, pred_mnist):\n",
        "                conf_matrix[true.item(), pred.item()] += 1\n",
        "            # Update confusion matrix for OOD\n",
        "            for true, pred in zip(labels_ood, pred_ood):\n",
        "                conf_matrix[true.item(), pred.item()] += 1\n",
        "    print(f\"Accuracy on MNIST data: {acc_mnist * 100:.2f}%\")\n",
        "    print(f\"Accuracy on OOD (Unknown) data: {acc_ood * 100:.2f}%\")\n",
        "    # Plot confusion matrix (10 MNIST classes + 1 OOD class)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[str(i) for i in range(10)] + [\"Unknown\"],\n",
        "                yticklabels=[str(i) for i in range(10)] + [\"Unknown\"])\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.title(f\"Confusion Matrix - OSR result, Total accuracy: {acc_total * 100:.2f}%\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "acc_mnist, acc_ood, acc_total = eval_model(osr_model, combined_ds_loader, device)\n",
        "OSR_cm(osr_model, combined_ds_loader, acc_mnist, acc_ood, acc_total)\n",
        "\n",
        "# t-SNE and/or PCA visualization (optional)\n",
        "def visualize_embeddings(model, data_loader, n_components=2):\n",
        "\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, label in data_loader:\n",
        "            data, label = data.to(device), label.to(device)\n",
        "\n",
        "            # Get embeddings from the model's intermediate layer (before final classification)\n",
        "            outputs, _, _, _, _ = model(data)\n",
        "            embedded_vector = model.encoder(data)\n",
        "\n",
        "            # Reshape the embedded vector to 2D: (batch_size, features)\n",
        "            embedded_vector = embedded_vector.view(embedded_vector.size(0), -1) # Flatten the feature map\n",
        "\n",
        "            probas, y_pred = torch.max(outputs, 1)\n",
        "\n",
        "            embeddings.append(embedded_vector.cpu().numpy())  # Using the raw output as embeddings\n",
        "            predictions.append(y_pred.cpu().numpy())\n",
        "\n",
        "    embeddings = np.concatenate(embeddings, axis=0)\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    reducer = TSNE(n_components=n_components)\n",
        "    reduced_embeddings = reducer.fit_transform(embeddings)\n",
        "\n",
        "    # Plot the reduced embeddings\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    scatter = plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=predictions, cmap='tab10', s=5)\n",
        "    plt.colorbar(scatter, ticks=range(12), label='Predicted Class')\n",
        "    plt.xlabel('Component 1')\n",
        "    plt.ylabel('Component 2')\n",
        "    plt.title('TSNE Visualization of Test Data Embeddings')\n",
        "    plt.show()\n",
        "\n",
        "visualize_embeddings(osr_model, combined_ds_loader)\n",
        "# Additional figures (optional)\n"
      ],
      "metadata": {
        "id": "sMyAzd-4YP-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation - Unknown Dataset"
      ],
      "metadata": {
        "id": "1xE41sHlYwtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "osr_dataset = \"\" #change to actual path\n",
        "combined_osr_ds = CombinedDataset(mnist_test_subset, osr_dataset)\n",
        "combined_osr_ds_loader = DataLoader(combined_ds, batch_size=1024, shuffle=True)\n",
        "\n",
        "# Load the trained models weights\n",
        "osr_model = OSR_model()\n",
        "osr_model.load_state_dict(torch.load('./OSR model.pth'))\n",
        "osr_model.to(device)\n",
        "osr_model.eval()\n",
        "\n",
        "# OOD results\n",
        "OOD_res(osr_model, combined_osr_ds_loader)\n",
        "\n",
        "# OSR results\n",
        "acc_mnist, acc_ood, acc_total = eval_model(osr_model, combined_osr_ds_loader, device)\n",
        "OSR_cm(osr_model, combined_osr_ds_loader, acc_mnist, acc_ood, acc_total)"
      ],
      "metadata": {
        "id": "OhNEvqK2Y1ie"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}